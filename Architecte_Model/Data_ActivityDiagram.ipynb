{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8507,
     "status": "ok",
     "timestamp": 1748605547235,
     "user": {
      "displayName": "chaymae merhrioui",
      "userId": "10667249281675888421"
     },
     "user_tz": -60
    },
    "id": "NbbTZNS6AkF5",
    "outputId": "a47c67c0-ccef-42cd-c5f7-21beda21ab2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/129.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m122.9/129.6 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.6/129.6 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "pip install groq -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 1465,
     "status": "ok",
     "timestamp": 1748605548674,
     "user": {
      "displayName": "chaymae merhrioui",
      "userId": "10667249281675888421"
     },
     "user_tz": -60
    },
    "id": "4HVf5cQ1Ap4-"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "from collections import deque\n",
    "import datetime\n",
    "import sys\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1748605566853,
     "user": {
      "displayName": "chaymae merhrioui",
      "userId": "10667249281675888421"
     },
     "user_tz": -60
    },
    "id": "FDjdEr58AxdL"
   },
   "outputs": [],
   "source": [
    "api_key = \"****\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KfkP9lNqA6tD"
   },
   "source": [
    "## function for extract Sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1748605591988,
     "user": {
      "displayName": "chaymae merhrioui",
      "userId": "10667249281675888421"
     },
     "user_tz": -60
    },
    "id": "_BVMnV9ZA7Yl"
   },
   "outputs": [],
   "source": [
    "def extract_sections(text, sections_to_extract):\n",
    "    extracted_sections = {}\n",
    "    current_section = None\n",
    "    lines = text.split('\\n')\n",
    "\n",
    "    for line in lines:\n",
    "        for section in sections_to_extract:\n",
    "            # (# Section) and (**Section:**)\n",
    "            pattern = r'^\\s*((?:#\\s+)|(?:\\*\\*))' + re.escape(section) + r'\\s*[:]?(\\*\\*?|$)'\n",
    "            if re.match(pattern, line, re.IGNORECASE):\n",
    "                current_section = section\n",
    "                extracted_sections[current_section] = []\n",
    "                break\n",
    "        if current_section and line.strip() != '':\n",
    "            if not re.match(r'^\\s*((?:#\\s+)|(?:\\*\\*))', line):\n",
    "                extracted_sections[current_section].append(line.strip())\n",
    "\n",
    "    return extracted_sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1748605600137,
     "user": {
      "displayName": "chaymae merhrioui",
      "userId": "10667249281675888421"
     },
     "user_tz": -60
    },
    "id": "QZYyvo3wA-D-"
   },
   "outputs": [],
   "source": [
    "class RateLimiter:\n",
    "    \"\"\"Manages rate limits for the Groq API\"\"\"\n",
    "\n",
    "    def __init__(self, requests_per_minute=30):\n",
    "        self.requests_per_minute = requests_per_minute\n",
    "        self.request_timestamps = deque(maxlen=requests_per_minute)\n",
    "\n",
    "    def wait_if_needed(self):\n",
    "        \"\"\"Waits if necessary to respect the requests per minute limit\"\"\"\n",
    "        current_time = time.time()\n",
    "\n",
    "        if len(self.request_timestamps) >= self.requests_per_minute:\n",
    "            oldest_request_time = self.request_timestamps[0]\n",
    "            time_since_oldest = current_time - oldest_request_time\n",
    "\n",
    "            if time_since_oldest < 60:\n",
    "                wait_time = 60 - time_since_oldest + 0.1\n",
    "                print(f\"Rate limit reached, waiting for {wait_time:.2f} seconds...\")\n",
    "                time.sleep(wait_time)\n",
    "\n",
    "        self.request_timestamps.append(time.time())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1X_wl6vrBCWN"
   },
   "source": [
    "## Function of Generating Activity Diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1748605698940,
     "user": {
      "displayName": "chaymae merhrioui",
      "userId": "10667249281675888421"
     },
     "user_tz": -60
    },
    "id": "iB_uOJP7BDK8"
   },
   "outputs": [],
   "source": [
    "def generate_activity_diagram(description_dict, rate_limiter):\n",
    "    url = \"https://api.groq.com/openai/v1/chat/completions\"\n",
    "\n",
    "    prompt = f\"\"\"You are an expert in UML modeling, specializing in sequence diagrams for automotive systems, particularly ADAS (Advanced Driver Assistance Systems).\n",
    "\n",
    "    TASK:\n",
    "    1. Carefully analyze the technical description below\n",
    "    2. Extract all necessary elements for a complete UML activity diagram:\n",
    "       - Actions and activities\n",
    "       - Decisions and conditional branches\n",
    "       - Merge points and forks\n",
    "       - Initial and final states\n",
    "       - Partitions/swimlanes if relevant to represent different actors\n",
    "       - Control flows and objects\n",
    "    3. Generate valid and complete PlantUML code that accurately represents the system's activity flow\n",
    "\n",
    "    TECHNICAL DESCRIPTION:\n",
    "\n",
    "    RESPONSE FORMAT:\n",
    "\n",
    "    1. Extracted structure:\n",
    "       - Main activities identified\n",
    "       - Identified decision points and conditions\n",
    "       - Identified parallel flows (if present)\n",
    "       - Actors or systems involved (for potential swimlanes)\n",
    "    2. Valid and complete PlantUML code for an activity diagram (including @startuml and @enduml)\n",
    "    3. Self-assessment: indicate your confidence level in the generated diagram (high/medium/low) and the assumptions you had to make\n",
    "    \"\"\"\n",
    "\n",
    "    for section, content in description_dict.items():\n",
    "        prompt += f\"\\n# {section}\\n\"\n",
    "        for line in content:\n",
    "            prompt += f\"{line}\\n\"\n",
    "\n",
    "    payload = {\n",
    "        \"model\": \"mistral-saba-24b\",\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "        \"temperature\": 0.2,\n",
    "        \"max_tokens\": 2048\n",
    "    }\n",
    "\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {api_key}\"\n",
    "    }\n",
    "\n",
    "    rate_limiter.wait_if_needed()\n",
    "\n",
    "    max_retries = 3\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = requests.post(url, headers=headers, data=json.dumps(payload))\n",
    "            response.raise_for_status()\n",
    "\n",
    "            print(f\"Status code: {response.status_code}\")\n",
    "            response_json = response.json()\n",
    "\n",
    "            if \"choices\" in response_json and len(response_json[\"choices\"]) > 0:\n",
    "                uml_code = response_json[\"choices\"][0][\"message\"][\"content\"]\n",
    "                return uml_code\n",
    "            else:\n",
    "                print(f\"Unusual response: {response_json}\")\n",
    "                if \"error\" in response_json:\n",
    "                    print(f\"Error: {response_json['error']}\")\n",
    "                return f\"UML generation error: {response_json}\"\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Attempt {attempt+1} failed: {e}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                if \"429\" in str(e):\n",
    "                    wait_time = 60 + 2 ** attempt\n",
    "                    print(f\"Rate limit error. Waiting for {wait_time} seconds...\")\n",
    "                else:\n",
    "                    wait_time = 2 ** attempt\n",
    "                    print(f\"Retrying in {wait_time} seconds...\")\n",
    "                time.sleep(wait_time)\n",
    "            else:\n",
    "                return f\"Failed after {max_retries} attempts: {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RtKXmmeVBfvl"
   },
   "source": [
    "## Process The Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1748606251374,
     "user": {
      "displayName": "chaymae merhrioui",
      "userId": "10667249281675888421"
     },
     "user_tz": -60
    },
    "id": "W2GZFR3jBYKy"
   },
   "outputs": [],
   "source": [
    "def process_csv_batch(file_path, batch_size=20, start_from=0):\n",
    "    \"\"\"Processes the CSV in batches without creating a progression file\"\"\"\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        total_rows = len(df)\n",
    "\n",
    "        print(f\"File loaded successfully: {total_rows} entries found\")\n",
    "        rate_limiter = RateLimiter(requests_per_minute=25)\n",
    "        start_idx = start_from\n",
    "        end_idx = min(start_idx + batch_size, total_rows)\n",
    "        print(f\"Processing lines {start_idx} to {end_idx-1}\")\n",
    "        results = []\n",
    "        output_file = f\"uml_activity_diagrams.csv\"\n",
    "\n",
    "        for index in range(start_idx, end_idx):\n",
    "            row = df.iloc[index]\n",
    "            try:\n",
    "                print(f\"Processing line {index}...\")\n",
    "                if 'Combined_Paragraph' not in row:\n",
    "                    print(f\"Error: 'Combined_Paragraph' column not found in line {index}\")\n",
    "                    print(f\"Available columns: {row.index.tolist()}\")\n",
    "                    continue\n",
    "\n",
    "                description = row['Combined_Paragraph']\n",
    "                if pd.isna(description) or not description.strip():\n",
    "                    print(f\"Line {index}: empty or invalid description, skipped\")\n",
    "                    continue\n",
    "\n",
    "                sections = extract_sections(description, sections_to_extract=[\n",
    "                    \"Technical Details\",\n",
    "                    \"Operational Steps\",\n",
    "                    \"Necessary Conditions\",\n",
    "                    \"Fault Detection and Management\",\n",
    "                    \"Performance Metrics\"\n",
    "                ])\n",
    "\n",
    "                structured_description = \"\"\n",
    "                for section, content in sections.items():\n",
    "                    structured_description += f\"# {section}\\n\"\n",
    "                    for line in content:\n",
    "                        structured_description += f\"{line}\\n\"\n",
    "                    structured_description += \"\\n\"\n",
    "\n",
    "                uml_content = generate_activity_diagram(sections, rate_limiter)\n",
    "                uml_structure = \"\"\n",
    "                uml_code = \"\"\n",
    "\n",
    "                if \"```\" in uml_content:\n",
    "                    parts = uml_content.split(\"```\")\n",
    "                    uml_structure = parts[0].strip()\n",
    "                    if len(parts) > 2:\n",
    "                        uml_code = parts[1].strip()\n",
    "                else:\n",
    "                    uml_structure = uml_content\n",
    "\n",
    "                result_dict = {\n",
    "                    'index': index,\n",
    "                    'description': structured_description.strip(),\n",
    "                    'uml_code': uml_code\n",
    "                }\n",
    "\n",
    "                if 'ID' in row:\n",
    "                    result_dict['ID'] = row['ID']\n",
    "\n",
    "                results.append(result_dict)\n",
    "                if index % 5 == 0 or index == end_idx - 1:\n",
    "                    temp_df = pd.DataFrame(results)\n",
    "                    temp_df.to_csv(output_file, index=False)\n",
    "                    print(f\"Progress saved: {len(results)}/{end_idx-start_idx} lines processed\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing line {index}: {str(e)}\")\n",
    "                with open(\"errors_processing.log\", \"a\") as log:\n",
    "                    log.write(f\"{datetime.datetime.now()} - Error line {index}: {str(e)}\\n\")\n",
    "                continue\n",
    "\n",
    "        if results:\n",
    "            output_df = pd.DataFrame(results)\n",
    "            output_df.to_csv(output_file, index=False)\n",
    "            print(f\"Results saved in '{output_file}'\")\n",
    "        else:\n",
    "            print(\"No results to save\")\n",
    "\n",
    "        return end_idx, total_rows\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Critical error processing the CSV: {str(e)}\")\n",
    "        return start_from, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10185,
     "status": "ok",
     "timestamp": 1748606264173,
     "user": {
      "displayName": "chaymae merhrioui",
      "userId": "10667249281675888421"
     },
     "user_tz": -60
    },
    "id": "SMFK8YAdB4Rh",
    "outputId": "519685be-1fc5-4f45-81d2-5e78ebb71737"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid argument for starting point: -f, using 0 by default.\n",
      "File loaded successfully: 10 entries found\n",
      "Processing lines 0 to 2\n",
      "Processing line 0...\n",
      "Status code: 200\n",
      "Progress saved: 1/3 lines processed\n",
      "Processing line 1...\n",
      "Status code: 200\n",
      "Processing line 2...\n",
      "Status code: 200\n",
      "Progress saved: 3/3 lines processed\n",
      "Results saved in 'uml_activity_diagrams.csv'\n",
      "Processing completed: 3/10 entries (30.0%)\n",
      "\n",
      "To continue processing from the next entry, run:\n",
      "python /usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py 3\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    FILE_PATH = '/content/adas_systems_step-02.csv'\n",
    "    BATCH_SIZE = 3\n",
    "\n",
    "    start_from = 0\n",
    "    if len(sys.argv) > 1:\n",
    "        try:\n",
    "            start_from = int(sys.argv[1])\n",
    "        except ValueError:\n",
    "            print(f\"Invalid argument for starting point: {sys.argv[1]}, using 0 by default.\")\n",
    "\n",
    "    current_position, total = process_csv_batch(FILE_PATH, BATCH_SIZE, start_from)\n",
    "\n",
    "    if total > 0:\n",
    "        print(f\"Processing completed: {current_position}/{total} entries ({current_position/total*100:.1f}%)\")\n",
    "\n",
    "        if current_position < total:\n",
    "            print(f\"\\nTo continue processing from the next entry, run:\")\n",
    "            print(f\"python {sys.argv[0]} {current_position}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5fWh6J_YCBrE"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNKCRnXFusVCX8EURYTA+Uq",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
