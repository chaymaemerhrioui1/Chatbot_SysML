{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3851,
     "status": "ok",
     "timestamp": 1748612229299,
     "user": {
      "displayName": "chaymae merhrioui",
      "userId": "10667249281675888421"
     },
     "user_tz": -60
    },
    "id": "TtPLjuTfYlrH",
    "outputId": "9be6aa03-7da9-4227-a79b-96a0f063fad4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/129.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m122.9/129.6 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.6/129.6 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "pip install groq -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 693,
     "status": "ok",
     "timestamp": 1748612229995,
     "user": {
      "displayName": "chaymae merhrioui",
      "userId": "10667249281675888421"
     },
     "user_tz": -60
    },
    "id": "8SXVHQA8Ysjs"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "from collections import deque\n",
    "import datetime\n",
    "import sys\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1748612257643,
     "user": {
      "displayName": "chaymae merhrioui",
      "userId": "10667249281675888421"
     },
     "user_tz": -60
    },
    "id": "8Wfyy-KQYuq1"
   },
   "outputs": [],
   "source": [
    "api_key = \"****\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G9WvKzZEYrgu"
   },
   "source": [
    "## function for extract Sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1748612258812,
     "user": {
      "displayName": "chaymae merhrioui",
      "userId": "10667249281675888421"
     },
     "user_tz": -60
    },
    "id": "FpFP5RDdY04K"
   },
   "outputs": [],
   "source": [
    "def extract_sections(text, sections_to_extract):\n",
    "    extracted_sections = {}\n",
    "    current_section = None\n",
    "    lines = text.split('\\n')\n",
    "\n",
    "    for line in lines:\n",
    "        for section in sections_to_extract:\n",
    "            # (# Section) and (**Section:**)\n",
    "            pattern = r'^\\s*((?:#\\s+)|(?:\\*\\*))' + re.escape(section) + r'\\s*[:]?(\\*\\*?|$)'\n",
    "            if re.match(pattern, line, re.IGNORECASE):\n",
    "                current_section = section\n",
    "                extracted_sections[current_section] = []\n",
    "                break\n",
    "        if current_section and line.strip() != '':\n",
    "            if not re.match(r'^\\s*((?:#\\s+)|(?:\\*\\*))', line):\n",
    "                extracted_sections[current_section].append(line.strip())\n",
    "\n",
    "    return extracted_sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1748612259195,
     "user": {
      "displayName": "chaymae merhrioui",
      "userId": "10667249281675888421"
     },
     "user_tz": -60
    },
    "id": "T_TwVF8vY5m8"
   },
   "outputs": [],
   "source": [
    "class RateLimiter:\n",
    "    \"\"\"Manages rate limits for the Groq API\"\"\"\n",
    "\n",
    "    def __init__(self, requests_per_minute=30):\n",
    "        self.requests_per_minute = requests_per_minute\n",
    "        self.request_timestamps = deque(maxlen=requests_per_minute)\n",
    "\n",
    "    def wait_if_needed(self):\n",
    "        \"\"\"Waits if necessary to respect the requests per minute limit\"\"\"\n",
    "        current_time = time.time()\n",
    "\n",
    "        if len(self.request_timestamps) >= self.requests_per_minute:\n",
    "            oldest_request_time = self.request_timestamps[0]\n",
    "            time_since_oldest = current_time - oldest_request_time\n",
    "\n",
    "            if time_since_oldest < 60:\n",
    "                wait_time = 60 - time_since_oldest + 0.1\n",
    "                print(f\"Rate limit reached, waiting for {wait_time:.2f} seconds...\")\n",
    "                time.sleep(wait_time)\n",
    "\n",
    "        self.request_timestamps.append(time.time())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WXQHcVt7Y-8s"
   },
   "source": [
    "## Function of Generating Class Diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1748613003480,
     "user": {
      "displayName": "chaymae merhrioui",
      "userId": "10667249281675888421"
     },
     "user_tz": -60
    },
    "id": "2ZtCq6cTY_eG"
   },
   "outputs": [],
   "source": [
    "def generate_class_diagram(description_dict, rate_limiter):\n",
    "    url = \"https://api.groq.com/openai/v1/chat/completions\"\n",
    "\n",
    "    prompt = f\"\"\"You are an expert in UML modeling, specializing in sequence diagrams for automotive systems, particularly ADAS (Advanced Driver Assistance Systems).\n",
    "\n",
    "    TASK:\n",
    "    1. Carefully analyze the technical description below\n",
    "    2. Extract all necessary elements for a complete UML class diagram:\n",
    "       - Classes and their attributes\n",
    "       - Methods and operations\n",
    "       - Relationships between classes (association, aggregation, composition, inheritance)\n",
    "       - Interfaces and implementations\n",
    "    3. Ensure that every class is logically related to at least one other class through one of the above relationships.\n",
    "    4. Generate valid and complete PlantUML code that accurately represents the system's architecture, with a focus on establishing clear and meaningful relationships between classes.\n",
    "\n",
    "    TECHNICAL DESCRIPTION:\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    for section, content in description_dict.items():\n",
    "        prompt += f\"\\n# {section}\\n\"\n",
    "        for line in content:\n",
    "            prompt += f\"{line}\\n\"\n",
    "\n",
    "    payload = {\n",
    "        \"model\": \"mistral-saba-24b\",\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "        \"temperature\": 0.2,\n",
    "        \"max_tokens\": 2048\n",
    "    }\n",
    "\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {api_key}\"\n",
    "    }\n",
    "\n",
    "    rate_limiter.wait_if_needed()\n",
    "\n",
    "    max_retries = 3\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = requests.post(url, headers=headers, data=json.dumps(payload))\n",
    "            response.raise_for_status()\n",
    "\n",
    "            print(f\"Status code: {response.status_code}\")\n",
    "            response_json = response.json()\n",
    "\n",
    "            if \"choices\" in response_json and len(response_json[\"choices\"]) > 0:\n",
    "                uml_code = response_json[\"choices\"][0][\"message\"][\"content\"]\n",
    "                return uml_code\n",
    "            else:\n",
    "                print(f\"Unusual response: {response_json}\")\n",
    "                if \"error\" in response_json:\n",
    "                    print(f\"Error: {response_json['error']}\")\n",
    "                return f\"UML generation error: {response_json}\"\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Attempt {attempt+1} failed: {e}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                if \"429\" in str(e):\n",
    "                    wait_time = 60 + 2 ** attempt\n",
    "                    print(f\"Rate limit error. Waiting for {wait_time} seconds...\")\n",
    "                else:\n",
    "                    wait_time = 2 ** attempt\n",
    "                    print(f\"Retrying in {wait_time} seconds...\")\n",
    "                time.sleep(wait_time)\n",
    "            else:\n",
    "                return f\"Failed after {max_retries} attempts: {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CmOFjOBUZk0z"
   },
   "source": [
    "## Process The Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1748613004492,
     "user": {
      "displayName": "chaymae merhrioui",
      "userId": "10667249281675888421"
     },
     "user_tz": -60
    },
    "id": "aLhi5d_WZfw9"
   },
   "outputs": [],
   "source": [
    "def process_csv_batch(file_path, batch_size=20, start_from=0):\n",
    "    \"\"\"Processes the CSV in batches without creating a progression file\"\"\"\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        total_rows = len(df)\n",
    "\n",
    "        print(f\"File loaded successfully: {total_rows} entries found\")\n",
    "        rate_limiter = RateLimiter(requests_per_minute=25)\n",
    "        start_idx = start_from\n",
    "        end_idx = min(start_idx + batch_size, total_rows)\n",
    "        print(f\"Processing lines {start_idx} to {end_idx-1}\")\n",
    "        results = []\n",
    "        output_file = f\"uml_class_diagrams.csv\"\n",
    "\n",
    "        for index in range(start_idx, end_idx):\n",
    "            row = df.iloc[index]\n",
    "            try:\n",
    "                print(f\"Processing line {index}...\")\n",
    "                if 'Combined_Paragraph' not in row:\n",
    "                    print(f\"Error: 'Combined_Paragraph' column not found in line {index}\")\n",
    "                    print(f\"Available columns: {row.index.tolist()}\")\n",
    "                    continue\n",
    "\n",
    "                description = row['Combined_Paragraph']\n",
    "                if pd.isna(description) or not description.strip():\n",
    "                    print(f\"Line {index}: empty or invalid description, skipped\")\n",
    "                    continue\n",
    "\n",
    "                sections = extract_sections(description, sections_to_extract=[\n",
    "                    \"Technical Details\",\n",
    "                    \"Interactions with Components and Systems\",\n",
    "                    \"User Interface and Controls\",\n",
    "                    \"Fault Detection and Management\"\n",
    "                ])\n",
    "\n",
    "                structured_description = \"\"\n",
    "                for section, content in sections.items():\n",
    "                    structured_description += f\"# {section}\\n\"\n",
    "                    for line in content:\n",
    "                        structured_description += f\"{line}\\n\"\n",
    "                    structured_description += \"\\n\"\n",
    "\n",
    "                uml_content = generate_class_diagram(sections, rate_limiter)\n",
    "                uml_structure = \"\"\n",
    "                uml_code = \"\"\n",
    "\n",
    "                if \"```\" in uml_content:\n",
    "                    parts = uml_content.split(\"```\")\n",
    "                    uml_structure = parts[0].strip()\n",
    "                    if len(parts) > 2:\n",
    "                        uml_code = parts[1].strip()\n",
    "                else:\n",
    "                    uml_structure = uml_content\n",
    "\n",
    "                result_dict = {\n",
    "                    'index': index,\n",
    "                    'description': structured_description.strip(),\n",
    "                    'uml_code': uml_code\n",
    "                }\n",
    "\n",
    "                if 'ID' in row:\n",
    "                    result_dict['ID'] = row['ID']\n",
    "\n",
    "                results.append(result_dict)\n",
    "                if index % 5 == 0 or index == end_idx - 1:\n",
    "                    temp_df = pd.DataFrame(results)\n",
    "                    temp_df.to_csv(output_file, index=False)\n",
    "                    print(f\"Progress saved: {len(results)}/{end_idx-start_idx} lines processed\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing line {index}: {str(e)}\")\n",
    "                with open(\"errors_processing.log\", \"a\") as log:\n",
    "                    log.write(f\"{datetime.datetime.now()} - Error line {index}: {str(e)}\\n\")\n",
    "                continue\n",
    "\n",
    "        if results:\n",
    "            output_df = pd.DataFrame(results)\n",
    "            output_df.to_csv(output_file, index=False)\n",
    "            print(f\"Results saved in '{output_file}'\")\n",
    "        else:\n",
    "            print(\"No results to save\")\n",
    "\n",
    "        return end_idx, total_rows\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Critical error processing the CSV: {str(e)}\")\n",
    "        return start_from, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 80822,
     "status": "ok",
     "timestamp": 1748613085839,
     "user": {
      "displayName": "chaymae merhrioui",
      "userId": "10667249281675888421"
     },
     "user_tz": -60
    },
    "id": "pDCmBWr_aEOg",
    "outputId": "53929ae2-8076-4496-f371-3a436b8ba1bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid argument for starting point: -f, using 0 by default.\n",
      "File loaded successfully: 10 entries found\n",
      "Processing lines 0 to 2\n",
      "Processing line 0...\n",
      "Status code: 200\n",
      "Progress saved: 1/3 lines processed\n",
      "Processing line 1...\n",
      "Status code: 200\n",
      "Processing line 2...\n",
      "Attempt 1 failed: 429 Client Error: Too Many Requests for url: https://api.groq.com/openai/v1/chat/completions\n",
      "Rate limit error. Waiting for 61 seconds...\n",
      "Status code: 200\n",
      "Progress saved: 3/3 lines processed\n",
      "Results saved in 'uml_class_diagrams.csv'\n",
      "Processing completed: 3/10 entries (30.0%)\n",
      "\n",
      "To continue processing from the next entry, run:\n",
      "python /usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py 3\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    FILE_PATH = '/content/adas_systems_step-02.csv'\n",
    "    BATCH_SIZE = 3\n",
    "\n",
    "    start_from = 0\n",
    "    if len(sys.argv) > 1:\n",
    "        try:\n",
    "            start_from = int(sys.argv[1])\n",
    "        except ValueError:\n",
    "            print(f\"Invalid argument for starting point: {sys.argv[1]}, using 0 by default.\")\n",
    "\n",
    "    current_position, total = process_csv_batch(FILE_PATH, BATCH_SIZE, start_from)\n",
    "\n",
    "    if total > 0:\n",
    "        print(f\"Processing completed: {current_position}/{total} entries ({current_position/total*100:.1f}%)\")\n",
    "\n",
    "        if current_position < total:\n",
    "            print(f\"\\nTo continue processing from the next entry, run:\")\n",
    "            print(f\"python {sys.argv[0]} {current_position}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aBL293dNaP5N"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNAH/MCCVI93UjCgS4wLfmp",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
